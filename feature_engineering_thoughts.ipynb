{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Jake Singleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC Taxi Rides: Reflection on (primarily) feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How did you find good featues for your model?**\n",
    "\n",
    "I did a lot of visualization in `final_modeling`. I found noticable relationships between hour of the day and day of the week with\n",
    "duration. For instance, rides are a lot shorter in duration in early hours of the morning, and on weekends they are\n",
    "also typically a bit shorter. So, we should include both hour and day of week in the features for our model.\n",
    "\n",
    "I also used log transformations to improve my model's accuracy. Taking the log of total_amount and fare_amount\n",
    "was very important in reducing my MAE, and taking the log of haversine and manhattan distances helped as well, \n",
    "but not as much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What worked and what didn't work?**\n",
    "\n",
    "Imporantly, I one-hot encoded features like day of week and hour to make sure they were weighted fairly. For example,\n",
    "we don't want to give Sunday a weighting of 6 (higher than all the others) just because it's the last day of the week. \n",
    "This made a lot of sense and was a fun application of feature engineering we've seen earlier in the class.\n",
    "\n",
    "As an example of something that didn't work, passenger count was not a very useful feature. It doesn't have a noticeable relationship with duration. Also, using a second dataset did not work for me at all. I thought\n",
    "using `collisions` might be beneficial, but doing any kind of merge with a meaningful amount of data was impossible \n",
    "because it was too expensive.\n",
    "\n",
    "Despite some of these issues, the results ended up being okay.\n",
    "The residual plots in `final_modeling` suggest our model struggles with taxi rides of high duration. However, the right skew in the histogram \n",
    "is minor, and the fact that the residuals are low around 600-800 seconds of duration suggests our model handles \n",
    "the average taxi ride pretty well (which is good)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What was surprising in the search for good features?**\n",
    "\n",
    "One thing that surprised me was the importance of logging total_amount and fare_amount. I didn't think this would be \n",
    "that important, but it improved my model by ~50 MAE (from 210ish validaiton MAE to 160ish).\n",
    "\n",
    "I also thought including both kinds of distances and both kinds of amounts might be redundant. But it turned out\n",
    "that including each of them gave me the best results.\n",
    "\n",
    "Lastly, finding good features was the hardest part of the project. There's no hard linear algebra (which has been the\n",
    "hardest part of the class) because sklearn basically does it all for you, but there's no well-defined way of \n",
    "choosing good features. My Kaggle MAE was around 338 until I tried logging total_amount and fare_amount, and \n",
    "this brought me down to 260ish MAE, a huge difference. Recognizing this\n",
    "and implementing it and seeing significant improvement was cool!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
